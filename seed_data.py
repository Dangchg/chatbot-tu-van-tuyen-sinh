# imports
import os
import glob
from dotenv import load_dotenv
import gradio as gr
from openai import OpenAI
import functools
from concurrent.futures import ThreadPoolExecutor
from g4f.client import Client
import time
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
import numpy as np
from sklearn.manifold import TSNE
import plotly.graph_objects as go


def load_data_from_folder(folders = glob.glob("Data/*")):
        
    text_loader_kwargs={'autodetect_encoding': True}
    metadata_sr = []
    documents = []
    for folder in folders:
        doc_type = os.path.basename(folder)
        loader = DirectoryLoader(folder, glob="**/*.md", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)
        folder_docs = loader.load()
        for doc in folder_docs:
            doc.metadata["doc_type"] = doc_type
            documents.append(doc)
    print("Total documents loaded:", len(documents))

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,  # Slightly smaller chunks for better retrieval
        chunk_overlap=50,  # Reduced overlap for performance
        separators=["\n\n", "\n", ". ", " ", ""]  # Better separation
    )

    chunks = text_splitter.split_documents(documents)
    print(f"Created {len(chunks)} chunks")

    doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)
    print(f"C√°c lo·∫°i t√†i li·ªáu ƒë√£ t√¨m th·∫•y: {', '.join(doc_types)}")

    return chunks
    

def vector_store1(chunks):
    embeddings = HuggingFaceEmbeddings(model_name="AITeamVN/Vietnamese_Embedding_v2")


    # ƒê·∫∑t t√™n cho database vector (c√≥ th·ªÉ t√πy ch·ªçn)
    db_name = "vector_db"

    # Ki·ªÉm tra n·∫øu database Chroma ƒë√£ t·ªìn t·∫°i, th√¨ x√≥a collection ƒë·ªÉ kh·ªüi ƒë·ªông l·∫°i t·ª´ ƒë·∫ßu
    if os.path.exists(db_name):
        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()

    # T·∫°o vector store b·∫±ng Chroma
    vectorstore = Chroma.from_documents(
        documents=chunks,              # Danh s√°ch c√°c ƒëo·∫°n vƒÉn b·∫£n ƒë√£ chia nh·ªè
        embedding=embeddings,          # H√†m embedding (v√≠ d·ª•: OpenAI ho·∫∑c HuggingFace)
        persist_directory=db_name      # Th∆∞ m·ª•c l∆∞u tr·ªØ database
    )
    # Ki·ªÉm tra s·ªë l∆∞·ª£ng document ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o vector store
    print(f"Vectorstore created with {vectorstore._collection.count()} documents")
    # L·∫•y ra b·ªô s∆∞u t·∫≠p vector t·ª´ vectorstore
    collection = vectorstore._collection

    # L·∫•y 1 embedding t·ª´ database
    sample_embedding = collection.get(limit=1, include=["embeddings"])["embeddings"][0]

    # Ki·ªÉm tra s·ªë chi·ªÅu (s·ªë ph·∫ßn t·ª≠ trong vector)
    dimensions = len(sample_embedding)
    print(f"The vectors have {dimensions:,} dimensions")
    # L·∫•y to√†n b·ªô vector, t√†i li·ªáu v√† metadata t·ª´ collection
    result = collection.get(include=['embeddings', 'documents', 'metadatas'])

    # ƒê∆∞a embedding v√†o m·∫£ng numpy
    vectors = np.array(result['embeddings'])

    # L∆∞u l·∫°i vƒÉn b·∫£n
    documents = result['documents']

    # Tr√≠ch lo·∫°i t√†i li·ªáu t·ª´ metadata (gi·∫£ s·ª≠ c√≥ 'doc_type')
    doc_types = [metadata['doc_type'] for metadata in result['metadatas']]

    # G√°n m√†u s·∫Øc t√πy theo lo·∫°i t√†i li·ªáu
    colors = [['blue', 'green', 'red'][['Dang', 'de_an_tuyen_sinh', 'diem_chuan'].index(t)] for t in doc_types]

    # 2D dimension!
    # Gi·∫£m s·ªë chi·ªÅu c·ªßa vector xu·ªëng 2D b·∫±ng t-SNE
    # (T-distributed Stochastic Neighbor Embedding)

    tsne = TSNE(n_components=2, random_state=42)
    reduced_vectors = tsne.fit_transform(vectors)

    # T·∫°o bi·ªÉu ƒë·ªì scatter 2D
    fig = go.Figure(data=[go.Scatter(
        x=reduced_vectors[:, 0],
        y=reduced_vectors[:, 1],
        mode='markers',
        marker=dict(size=5, color=colors, opacity=0.8),
        text=[f"Lo·∫°i: {t}<br>VƒÉn b·∫£n: {d[:100]}..." for t, d in zip(doc_types, documents)],
        hoverinfo='text'
    )])

    fig.update_layout(
        title='Bi·ªÉu ƒë·ªì 2D Chroma Vector Store',
        scene=dict(xaxis_title='x', yaxis_title='y'),
        width=800,
        height=600,
        margin=dict(r=20, b=10, l=10, t=40)
    )

    fig.show(renderer="browser")
    
    return vectorstore
def vector_store2(chunks):
    db_name = "vector_db"
    embeddings = HuggingFaceEmbeddings(model_name="AITeamVN/Vietnamese_Embedding_v2")
    if os.path.exists(db_name):  
        print("üìÇ ƒêang load Vector DB (ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥)...")
        vectorstore = Chroma(
            persist_directory=db_name,
            embedding_function=embeddings
        )
    return vectorstore