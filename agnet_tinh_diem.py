import os
import glob
from dotenv import load_dotenv

# LangChain Imports
from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_openai import ChatOpenAI
from langchain_classic.chains import ConversationalRetrievalChain
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
import gradio as gr
from seed_data import load_data_from_folder, vector_store1,vector_store2

# 4. HÃ€M Táº O HYBRID RETRIEVER (QUAN TRá»ŒNG)
# ---------------------------------------------------------
def create_hybrid_retriever(vectorstore, chunks):
    """
    Táº¡o bá»™ tÃ¬m kiáº¿m lai: Káº¿t há»£p Keyword (BM25) vÃ  Semantic (Vector).
    """
    print("ğŸ” Äang cáº¥u hÃ¬nh Hybrid Retrieval...")
    
    # 1. Keyword Retriever (BM25) - Tá»‘t cho tÃ¬m kiáº¿m tÃªn riÃªng, mÃ£ ngÃ nh, con sá»‘ chÃ­nh xÃ¡c
    bm25_retriever = BM25Retriever.from_documents(chunks)
    bm25_retriever.k = 10  # Láº¥y top 10 káº¿t quáº£ tá»« khÃ³a

    # 2. Vector Retriever (Chroma) - Tá»‘t cho tÃ¬m kiáº¿m ngá»¯ nghÄ©a, cÃ¢u há»i mÆ¡ há»“
    chroma_retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 100} # Láº¥y top 10 káº¿t quáº£ ngá»¯ nghÄ©a
    )

    # 3. Ensemble (Káº¿t há»£p)
    # weights=[0.4, 0.6]: 40% Æ°u tiÃªn tá»« khÃ³a, 60% Æ°u tiÃªn ngá»¯ nghÄ©a (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, chroma_retriever],
        weights=[0.4, 0.6]
    )
    
    return ensemble_retriever

def setup_rag_chain(retriever):
    """
    Káº¿t ná»‘i Retriever vá»›i LLM (OpenAI) Ä‘á»ƒ tÃ­nh toÃ¡n Ä‘iá»ƒm vÃ  gá»£i Ã½ trÆ°á»ng.
    """
    # DÃ¹ng temperature tháº¥p Ä‘á»ƒ tÃ­nh toÃ¡n chÃ­nh xÃ¡c
    llm = ChatOpenAI(
        api_key="sk-bnPOclUlNLW7xF40Xdi35PtWhXA2k8S6gprHkeHGP9XuWQY7",
        base_url="https://gpt1.shupremium.com/v1",
        temperature=0.1, 
        model_name="gpt-4o-mini",
    )

    memory = ConversationBufferWindowMemory(
        k=5, memory_key="chat_history", return_messages=True
    )

    # --- SYSTEM PROMPT: TÆ¯ DUY LOGIC (CHAIN OF THOUGHT) ---
    system_template = """Báº¡n lÃ  Trá»£ lÃ½ AI chuyÃªn vá» Tuyá»ƒn sinh Äáº¡i há»c. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tÃ­nh Ä‘iá»ƒm xÃ©t tuyá»ƒn vÃ  Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng Ä‘á»— cá»§a há»c sinh.

    HÃƒY THá»°C HIá»†N SUY LUáº¬N THEO CÃC BÆ¯á»šC SAU (Báº®T BUá»˜C):
    
    BÆ°á»›c 1: PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘áº§u vÃ o
    - XÃ¡c Ä‘á»‹nh Ä‘iá»ƒm cÃ¡c mÃ´n (ToÃ¡n, LÃ½, HÃ³a, VÄƒn, Anh...) vÃ  chá»©ng chá»‰ (IELTS, TOEIC...) tá»« cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
    
    BÆ°á»›c 2: TÃ¬m kiáº¿m thÃ´ng tin trong Ngá»¯ cáº£nh (Context)
    - TÃ¬m tÃªn trÆ°á»ng Ä‘áº¡i há»c mÃ  ngÆ°á»i dÃ¹ng quan tÃ¢m (hoáº·c táº¥t cáº£ cÃ¡c trÆ°á»ng cÃ³ trong ngá»¯ cáº£nh).
    - TÃ¬m "Báº£ng quy Ä‘á»•i Ä‘iá»ƒm IELTS" cá»§a trÆ°á»ng Ä‘Ã³ (náº¿u cÃ³ IELTS).
    - TÃ¬m "CÃ´ng thá»©c tÃ­nh Ä‘iá»ƒm" cá»§a trÆ°á»ng Ä‘Ã³.
    - TÃ¬m "Äiá»ƒm chuáº©n" hoáº·c "Äiá»ƒm trÃºng tuyá»ƒn" cÃ¡c nÄƒm trÆ°á»›c.

    BÆ°á»›c 3: Thá»±c hiá»‡n tÃ­nh toÃ¡n (Hiá»ƒn thá»‹ chi tiáº¿t tá»«ng phÃ©p tÃ­nh)
    - Náº¿u cÃ³ IELTS: Quy Ä‘á»•i IELTS sang Ä‘iá»ƒm thi theo quy cháº¿ tÃ¬m Ä‘Æ°á»£c á»Ÿ BÆ°á»›c 2.
    - Ãp dá»¥ng cÃ´ng thá»©c: Thay sá»‘ vÃ o Ä‘á»ƒ tÃ­nh Tá»•ng Ä‘iá»ƒm xÃ©t tuyá»ƒn.
    
    BÆ°á»›c 4: ÄÆ°a ra Ä‘á» nghá»‹ vÃ  Káº¿t luáº­n
    - So sÃ¡nh Tá»•ng Ä‘iá»ƒm vá»«a tÃ­nh vá»›i Äiá»ƒm chuáº©n trong ngá»¯ cáº£nh.
    - ÄÆ°a ra nháº­n Ä‘á»‹nh: "Kháº£ nÄƒng Ä‘á»— Cao/Tháº¥p/An toÃ n".
    - Gá»£i Ã½ ngÃ nh há»c phÃ¹ há»£p vá»›i sá»‘ Ä‘iá»ƒm Ä‘Ã³.

    LÆ¯U Ã QUAN TRá»ŒNG:
    - Náº¿u khÃ´ng tÃ¬m tháº¥y cÃ´ng thá»©c tÃ­nh hoáº·c báº£ng quy Ä‘á»•i trong ngá»¯ cáº£nh, hÃ£y tráº£ lá»i trung thá»±c: "Xin lá»—i, dá»¯ liá»‡u hiá»‡n táº¡i chÆ°a cáº­p nháº­t cÃ¡ch tÃ­nh Ä‘iá»ƒm cho trÆ°á»ng nÃ y".
    - Tuyá»‡t Ä‘á»‘i KHÃ”NG tá»± bá»‹a ra cÃ´ng thá»©c tÃ­nh Ä‘iá»ƒm."""


    

    # --- HUMAN PROMPT ---
    human_template = """
    Dá»¯ liá»‡u tham kháº£o (Context):
    {context}

    CÃ¢u há»i/Há»“ sÆ¡ cá»§a há»c sinh (Question): 
    {question}
    
    HÃ£y tÃ­nh toÃ¡n vÃ  tÆ° váº¥n chi tiáº¿t:
    """

    # Táº¡o Prompt
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", human_template),
    ])

    # Táº¡o Chain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        verbose=True, # Báº­t lÃªn Ä‘á»ƒ xem log tÃ­nh toÃ¡n
        combine_docs_chain_kwargs={"prompt": chat_prompt}
    )
    
    return qa_chain

# 6. MAIN & GIAO DIá»†N
# ---------------------------------------------------------
# Biáº¿n toÃ n cá»¥c Ä‘á»ƒ lÆ°u chain
global_chain = None

def init_system1():
    global global_chain
    # 1. Load data
    chunks = load_data_from_folder(folders = glob.glob("Data/*"))
    # 2. Vector DB
    vector_db = vector_store1(chunks)
    # 3. Retriever
    hybrid_retriever = create_hybrid_retriever(vector_db, chunks)
    # 4. Setup Chain
    global_chain = setup_rag_chain(hybrid_retriever)
    print("ğŸš€ Há»‡ thá»‘ng Ä‘Ã£ khá»Ÿi Ä‘á»™ng xong!")

def init_system2():
    global global_chain
    # 1. Load data
    chunks = load_data_from_folder(folders = glob.glob("Data/*"))
    # 2. Vector DB
    vector_db = vector_store2(chunks)
    # 3. Retriever
    hybrid_retriever = create_hybrid_retriever(vector_db, chunks)
    # 4. Setup Chain
    global_chain = setup_rag_chain(hybrid_retriever)

def chat_interface(message, history):
    """HÃ m xá»­ lÃ½ chat cho Gradio"""
    if global_chain is None:
        return "Há»‡ thá»‘ng Ä‘ang khá»Ÿi Ä‘á»™ng, vui lÃ²ng Ä‘á»£i..."
    
    try:
        response = global_chain.invoke({"question": message})
        return response["answer"]
    except Exception as e:
        return f"ÄÃ£ xáº£y ra lá»—i: {str(e)}"

# Cháº¡y há»‡ thá»‘ng
if __name__ == "__main__":
    print("======================================")
    print("ğŸš€ Há»† THá»NG TRá»¢ LÃ TUYá»‚N SINH (Hybrid RAG)")
    print("1. Táº¡o láº¡i Vector DB tá»« Ä‘áº§u")
    print("2. KhÃ´ng táº¡o láº¡i Vector DB (cháº¡y luÃ´n)")
    print("======================================")

    choice = input("ğŸ‘‰ Nháº­p lá»±a chá»n (1 hoáº·c 2): ").strip()

    if choice == "1":
        print("ğŸ”„ Äang táº¡o láº¡i Vector DB...")
        # Khá»Ÿi táº¡o pipeline
        init_system1()
    else:
        print("ğŸ”„ KhÃ´ng táº¡o láº¡i Vector DB (cháº¡y luÃ´n)")
        # Khá»Ÿi táº¡o pipeline
        init_system2()
        
    # Khá»Ÿi cháº¡y giao diá»‡n
    print("ğŸŒ Äang má»Ÿ giao diá»‡n Gradio...")
    gr.ChatInterface(
        chat_interface, 
        type="messages",
        title="Trá»£ lÃ½ Tuyá»ƒn sinh Äáº¡i há»c (Hybrid RAG)",
        description="Há»i Ä‘Ã¡p thÃ´ng tin tuyá»ƒn sinh sá»­ dá»¥ng cÃ´ng nghá»‡ tÃ¬m kiáº¿m lai (Tá»« khÃ³a + Ngá»¯ nghÄ©a)."
    ).launch()