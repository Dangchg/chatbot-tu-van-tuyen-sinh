import os
import glob
from dotenv import load_dotenv

# LangChain Imports
from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_openai import ChatOpenAI
from langchain_classic.chains import ConversationalRetrievalChain
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
import gradio as gr
from seed_data import load_data_from_folder, vector_store1,vector_store2




# 4. H√ÄM T·∫†O HYBRID RETRIEVER (QUAN TR·ªåNG)
# ---------------------------------------------------------
def create_hybrid_retriever(vectorstore, chunks):
    """
    T·∫°o b·ªô t√¨m ki·∫øm lai: K·∫øt h·ª£p Keyword (BM25) v√† Semantic (Vector).
    """
    print("üîç ƒêang c·∫•u h√¨nh Hybrid Retrieval...")
    
    # 1. Keyword Retriever (BM25) - T·ªët cho t√¨m ki·∫øm t√™n ri√™ng, m√£ ng√†nh, con s·ªë ch√≠nh x√°c
    bm25_retriever = BM25Retriever.from_documents(chunks)
    bm25_retriever.k = 10  # L·∫•y top 10 k·∫øt qu·∫£ t·ª´ kh√≥a

    # 2. Vector Retriever (Chroma) - T·ªët cho t√¨m ki·∫øm ng·ªØ nghƒ©a, c√¢u h·ªèi m∆° h·ªì
    chroma_retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 100} # L·∫•y top 100 k·∫øt qu·∫£ ng·ªØ nghƒ©a
    )

    # 3. Ensemble (K·∫øt h·ª£p)
    # weights=[0.4, 0.6]: 40% ∆∞u ti√™n t·ª´ kh√≥a, 60% ∆∞u ti√™n ng·ªØ nghƒ©a (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, chroma_retriever],
        weights=[0.4, 0.6]
    )
    
    return ensemble_retriever

# 5. H√ÄM KH·ªûI T·∫†O CHATBOT CHAIN
# ---------------------------------------------------------
def setup_rag_chain(retriever):
    """
    K·∫øt n·ªëi Retriever v·ªõi LLM (OpenAI) v√† b·ªô nh·ªõ h·ªôi tho·∫°i.
    """
    # C·∫•u h√¨nh LLM
    # B·∫°n c√≥ th·ªÉ thay ƒë·ªïi base_url n·∫øu d√πng proxy ho·∫∑c service kh√°c
    '''llm = ChatOpenAI(
        model_name="gpt-4o-mini", # Ho·∫∑c gpt-3.5-turbo
        temperature=0.3,          # Gi·ªØ nhi·ªát ƒë·ªô th·∫•p ƒë·ªÉ c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, √≠t b·ªãa
        streaming=True
    )'''

    llm = ChatOpenAI(
    api_key="sk-bnPOclUlNLW7xF40Xdi35PtWhXA2k8S6gprHkeHGP9XuWQY7",
    base_url="https://gpt1.shupremium.com/v1",
    temperature=0.7, 
    model_name="gpt-4o-mini",
    )


    # B·ªô nh·ªõ h·ªôi tho·∫°i (Nh·ªõ 5 c·∫∑p c√¢u h·ªèi-tr·∫£ l·ªùi g·∫ßn nh·∫•t)
    memory = ConversationBufferWindowMemory(
        k=10,
        memory_key="chat_history",
        return_messages=True
    )

    system_template = (
    "B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n tuy·ªÉn sinh ƒë·∫°i h·ªçc t·∫°i Vi·ªát Nam . "
    "Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn ƒëi·ªÉm tuy·ªÉn sinh ƒë·∫ßu v√†o, quy ch·∫ø tuy·ªÉn sinh, tr∆∞·ªùng h·ªçc, c√°c ph∆∞∆°ng th·ª©c tuy·ªÉn sinh v√† c√°ch t√≠nh ƒëi·ªÉm theo c√°ch ph∆∞∆°ng th·ª©c tuy·ªÉn sinh m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c. "
    "N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i r√µ r·∫±ng b·∫°n kh√¥ng bi·∫øt. "
    "Tuy·ªát ƒë·ªëi kh√¥ng b·ªãa ra th√¥ng tin n·∫øu kh√¥ng c√≥ ng·ªØ c·∫£nh li√™n quan ƒë∆∞·ª£c cung c·∫•p."
    "H√£y s·ª≠ d·ª•ng th√¥ng tin ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi ·ªü cu·ªëi:"

    )


    human_template = """S·ª≠ d·ª•ng th√¥ng tin ng·ªØ c·∫£nh sau ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi:
    
    Ng·ªØ c·∫£nh (Context):
    {context}

    C√¢u h·ªèi (Question): {question}
    """

    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", human_template),
    ])

    # T·∫°o Chain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        verbose=True,
        combine_docs_chain_kwargs={"prompt": chat_prompt} 
    )
    
    return qa_chain

# 6. MAIN & GIAO DI·ªÜN
# ---------------------------------------------------------
# Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u chain
global_chain = None

def init_system1():
    global global_chain
    # 1. Load data
    chunks = load_data_from_folder(folders = glob.glob("Data/*"))
    # 2. Vector DB
    vector_db = vector_store1(chunks)
    # 3. Retriever
    hybrid_retriever = create_hybrid_retriever(vector_db, chunks)
    # 4. Setup Chain
    global_chain = setup_rag_chain(hybrid_retriever)
    print("üöÄ H·ªá th·ªëng ƒë√£ kh·ªüi ƒë·ªông xong!")

def init_system2():
    global global_chain
    # 1. Load data
    chunks = load_data_from_folder(folders = glob.glob("Data/*"))
    # 2. Vector DB
    vector_db = vector_store2(chunks)
    # 3. Retriever
    hybrid_retriever = create_hybrid_retriever(vector_db, chunks)
    # 4. Setup Chain
    global_chain = setup_rag_chain(hybrid_retriever)

def chat_interface(message, history):
    """H√†m x·ª≠ l√Ω chat cho Gradio"""
    if global_chain is None:
        return "H·ªá th·ªëng ƒëang kh·ªüi ƒë·ªông, vui l√≤ng ƒë·ª£i..."
    
    try:
        response = global_chain.invoke({"question": message})
        return response["answer"]
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói: {str(e)}"

# Ch·∫°y h·ªá th·ªëng
if __name__ == "__main__":
    print("======================================")
    print("üöÄ H·ªÜ TH·ªêNG TR·ª¢ L√ù TUY·ªÇN SINH (Hybrid RAG)")
    print("1. T·∫°o l·∫°i Vector DB t·ª´ ƒë·∫ßu")
    print("2. Kh√¥ng t·∫°o l·∫°i Vector DB (ch·∫°y lu√¥n)")
    print("======================================")

    choice = input("üëâ Nh·∫≠p l·ª±a ch·ªçn (1 ho·∫∑c 2): ").strip()

    if choice == "1":
        print("üîÑ ƒêang t·∫°o l·∫°i Vector DB...")
        # Kh·ªüi t·∫°o pipeline
        init_system1()
    else:
        print("üîÑ Kh√¥ng t·∫°o l·∫°i Vector DB (ch·∫°y lu√¥n)")
        # Kh·ªüi t·∫°o pipeline
        init_system2()
        
    # Kh·ªüi ch·∫°y giao di·ªán
    print("üåê ƒêang m·ªü giao di·ªán Gradio...")
    gr.ChatInterface(
        chat_interface, 
        type="messages",
        title="Tr·ª£ l√Ω Tuy·ªÉn sinh ƒê·∫°i h·ªçc (Hybrid RAG)",
        description="H·ªèi ƒë√°p th√¥ng tin tuy·ªÉn sinh s·ª≠ d·ª•ng c√¥ng ngh·ªá t√¨m ki·∫øm lai (T·ª´ kh√≥a + Ng·ªØ nghƒ©a)."
    ).launch()