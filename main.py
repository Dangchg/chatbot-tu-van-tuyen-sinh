from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# 1. KHá»I Táº O LLM CHO ROUTER (NÃªn dÃ¹ng model nhanh, ráº»)
router_llm = ChatOpenAI(
    api_key="sk-bnPOclUlNLW7xF40Xdi35PtWhXA2k8S6gprHkeHGP9XuWQY7",
    base_url="https://gpt1.shupremium.com/v1",
    temperature=0, # Báº¯t buá»™c báº±ng 0 Ä‘á»ƒ phÃ¢n loáº¡i chÃ­nh xÃ¡c
    model_name="gpt-4o-mini"
)

# 2. HÃ€M PHÃ‚N LOáº I YÃŠU Cáº¦U (THE ROUTER)
def classify_intent(question):
    """
    PhÃ¢n tÃ­ch cÃ¢u há»i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh ngÆ°á»i dÃ¹ng muá»‘n gÃ¬.
    Output: 'CALCULATION', 'ADVISORY', hoáº·c 'INFO'
    """
    system_instruction = """
    Báº¡n lÃ  má»™t bá»™ Ä‘á»‹nh tuyáº¿n (Router) thÃ´ng minh. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phÃ¢n loáº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ o 1 trong 3 nhÃ³m sau:

    1. 'CALCULATION': Náº¿u ngÆ°á»i dÃ¹ng cung cáº¥p Ä‘iá»ƒm sá»‘ chi tiáº¿t cÃ¡c mÃ´n (ToÃ¡n, LÃ½, Anh, IELTS...) vÃ  yÃªu cáº§u tÃ­nh Ä‘iá»ƒm xÃ©t tuyá»ƒn.
       - VÃ­ dá»¥: "IELTS 7.0 toÃ¡n 8 lÃ½ 9 thÃ¬ bao nhiÃªu Ä‘iá»ƒm?", "TÃ­nh Ä‘iá»ƒm giÃºp mÃ¬nh vá»›i cÃ¡c Ä‘iá»ƒm sau..."

    2. 'ADVISORY': Náº¿u ngÆ°á»i dÃ¹ng cung cáº¥p Tá»”NG ÄIá»‚M (hoáº·c Ä‘iá»ƒm Ã¡ng chá»«ng) vÃ  há»i cÃ³ thá»ƒ Ä‘á»— trÆ°á»ng nÃ o/ngÃ nh nÃ o.
       - VÃ­ dá»¥: "MÃ¬nh Ä‘Æ°á»£c 24 Ä‘iá»ƒm nÃªn vÃ o trÆ°á»ng nÃ o?", "25 Ä‘iá»ƒm cÃ³ Ä‘á»— Kinh táº¿ quá»‘c dÃ¢n khÃ´ng?", "TÆ° váº¥n chá»n trÆ°á»ng khá»‘i A".

    3. 'INFO': CÃ¡c cÃ¢u há»i thÃ´ng tin chung, quy cháº¿, há»c phÃ­, lá»‹ch sá»­, kÃ½ tÃºc xÃ¡... khÃ´ng liÃªn quan Ä‘áº¿n tÃ­nh toÃ¡n cá»¥ thá»ƒ.
       - VÃ­ dá»¥: "Há»c phÃ­ BÃ¡ch Khoa lÃ  bao nhiÃªu?", "TrÆ°á»ng cÃ³ máº¥y cÆ¡ sá»Ÿ?", "Quy cháº¿ tuyá»ƒn tháº³ng tháº¿ nÃ o?".

    CHá»ˆ TRáº¢ Vá»€ DUY NHáº¤T 1 Tá»ª KHÃ“A: CALCULATION, ADVISORY, HOáº¶C INFO. KHÃ”NG GIáº¢I THÃCH GÃŒ THÃŠM.
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_instruction),
        ("human", "{question}")
    ])

    # Táº¡o chain phÃ¢n loáº¡i
    route_chain = prompt | router_llm | StrOutputParser()
    
    # Thá»±c thi
    category = route_chain.invoke({"question": question})
    return category.strip().upper()

# 3. Cáº¤U HÃŒNH 3 AGENT (TÃ¡i sá»­ dá»¥ng cÃ¡c prompt báº¡n Ä‘Ã£ lÃ m)
# --------------------------------------------------------

def get_calculation_chain(retriever, llm, memory):
    # Copy code pháº§n Prompt tÃ­nh toÃ¡n (IELTS + ToÃ¡n...) vÃ o Ä‘Ã¢y
    system_template = "Báº¡n lÃ  mÃ¡y tÃ­nh tuyá»ƒn sinh. HÃ£y trÃ­ch xuáº¥t Ä‘iá»ƒm vÃ  tÃ­nh toÃ¡n chi tiáº¿t..."
    prompt = ChatPromptTemplate.from_messages([("system", system_template), ("human", "{context}\n\n{question}")])
    return ConversationalRetrievalChain.from_llm(llm, retriever, memory, combine_docs_chain_kwargs={"prompt": prompt})

def get_advisory_chain(retriever, llm, memory):
    # Copy code pháº§n Prompt tÆ° váº¥n ngÆ°á»£c (24 Ä‘iá»ƒm Ä‘á»— trÆ°á»ng nÃ o) vÃ o Ä‘Ã¢y
    system_template = "Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n. HÃ£y lá»c cÃ¡c trÆ°á»ng phÃ¹ há»£p vá»›i má»©c Ä‘iá»ƒm tá»•ng..."
    prompt = ChatPromptTemplate.from_messages([("system", system_template), ("human", "{context}\n\n{question}")])
    return ConversationalRetrievalChain.from_llm(llm, retriever, memory, combine_docs_chain_kwargs={"prompt": prompt})

def get_general_info_chain(retriever, llm, memory):
    # Copy code pháº§n Prompt há»i Ä‘Ã¡p thÃ´ng thÆ°á»ng vÃ o Ä‘Ã¢y
    system_template = "Báº¡n lÃ  trá»£ lÃ½ áº£o. HÃ£y tráº£ lá»i thÃ´ng tin dá»±a trÃªn ngá»¯ cáº£nh..."
    prompt = ChatPromptTemplate.from_messages([("system", system_template), ("human", "{context}\n\n{question}")])
    return ConversationalRetrievalChain.from_llm(llm, retriever, memory, combine_docs_chain_kwargs={"prompt": prompt})

# 4. HÃ€M Xá»¬ LÃ CHÃNH (MAIN HANDLER)
# --------------------------------------------------------
def main_chat_handler(message, history, retriever, memory):
    """
    ÄÃ¢y lÃ  hÃ m sáº½ Ä‘Æ°á»£c gá»i bá»Ÿi Gradio
    """
    print(f"ğŸ“¥ CÃ¢u há»i nháº­n Ä‘Æ°á»£c: {message}")
    
    # BÆ¯á»šC 1: Äá»ŠNH TUYáº¾N
    intent = classify_intent(message)
    print(f"ğŸ”€ Router quyáº¿t Ä‘á»‹nh chuyá»ƒn hÆ°á»›ng sang: {intent}")

    # Cáº¥u hÃ¬nh LLM chung cho cÃ¡c Agent con
    llm_worker = ChatOpenAI(
        api_key="sk-bnPOclUlNLW7xF40Xdi35PtWhXA2k8S6gprHkeHGP9XuWQY7",
        base_url="https://gpt1.shupremium.com/v1",
        temperature=0.1, 
        model_name="gpt-4o-mini"
    )

    # BÆ¯á»šC 2: CHá»ŒN CHAIN PHÃ™ Há»¢P
    if intent == "CALCULATION":
        active_chain = get_calculation_chain(retriever, llm_worker, memory)
        prefix = "ğŸ§® [Cháº¿ Ä‘á»™ TÃ­nh Äiá»ƒm]: " # (Optional) Äá»ƒ debug xem Ä‘Ãºng ko
    elif intent == "ADVISORY":
        active_chain = get_advisory_chain(retriever, llm_worker, memory)
        prefix = "ğŸ“ [Cháº¿ Ä‘á»™ TÆ° Váº¥n Chá»n TrÆ°á»ng]: "
    else:
        active_chain = get_general_info_chain(retriever, llm_worker, memory)
        prefix = "â„¹ï¸ [Cháº¿ Ä‘á»™ ThÃ´ng Tin]: "

    # BÆ¯á»šC 3: TRáº¢ Lá»œI
    try:
        response = active_chain.invoke({"question": message})
        # return prefix + response["answer"] # CÃ³ thá»ƒ bá» prefix náº¿u muá»‘n tá»± nhiÃªn
        return response["answer"]
    except Exception as e:
        return f"Lá»—i há»‡ thá»‘ng: {str(e)}"

# 5. Cáº¬P NHáº¬T GRADIO
# Trong pháº§n main, báº¡n chá»‰ cáº§n gá»i main_chat_handler